{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/2017/12/12/tuning-splunk-when-max-concurrent-searches-are-reached/",
    "result": {"data":{"site":{"siteMetadata":{"title":"RFaircloth Data Nerd"}},"markdownRemark":{"id":"e97ea5a6-c280-5190-895b-32ec5bcc2673","excerpt":"Your searches are queued but you have cores, memory and IO to spare? Tuning your limits can allow Splunk to utilize “more” of your hardware when scaled up…","html":"<p>Your searches are queued but you have cores, memory and IO to spare? Tuning your limits can allow Splunk to utilize “more” of your hardware when scaled up instances are in use.</p>\n<p><strong>Warnings</strong></p>\n<p>This approach is <strong>NOT</strong> useful when searches run <strong>LONG.</strong> If regular searches such as datamodel acceleration, summary and reporting searches are not completing inside of the expected/required time constraints this information could make the symptoms <em><span style=\"text-decoration: underline;\"><strong>worse</strong></span></em>.</p>\n<p>This approach is useful when searches consistently execute faster than the required times for datamodel acceleration, summary and reporting and additional searches are queued while the utilization of cpu, memory, storage IOPS, storage bandwidth are well below the <strong><em>validated</em></strong> capacity of the infrastructure.</p>\n<h2>Details</h2>\n<p>First in all certain versions of Splunk apply the following setting to disable a feature that can slow search initialization.</p>\n<p>$SPLUNK_HOME/etc/local/limits.conf</p>\n<p>$SPLUNK_HOME/etc/master-apps/_cluster/local/limits.conf</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[search]\n#Splunk version >=6.5.0 &lt;6.5.6\n#Splunk version >=6.6.0 &lt;6.6.3\n#Not required >7.0.0\n#SPL-136845 Review future release notes to determine if this can be reverted to auto\nmax_searches_per_process = 1</code></pre></div>\n<p>On the search head only where DMA is utilized (ES) update the following</p>\n<p>$SPLUNK_HOME/etc/local/limits.conf</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">#this is useful when you have ad-hoc to spare but are skipping searches (ES I'm looking at you) or other\n# home grown or similar things\n[scheduler]\nmax_searches_perc = 75\nauto_summary_perc = 100</code></pre></div>\n<p>Evaluate the load percentage on the search heads and indexers including memory, cpu utilized and memory utilized. We can increase the value of base_max_searches in increments of 10 to allow more concurrent searches per SH until one of the following occurs</p>\n<ul>\n<li>CPU or memory utilization is 60% on IDX or SH</li>\n<li>IOPS or storage throughput hits ceiling and no longer increases decrease the system is fully utilized to prevent failure due to unexpected load decrement the base_max_searches value by 10 and confirm IOPS is no longer constant.</li>\n<li>Skipping /queuing no longer occurs (increase by 1-3 additional units from this point to provide some “head room”</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">#limits.conf set SH only\n[search]\n#base value is 6 increase by 10 until utilization on IDX or SH is at 60% CPU/memory starting with 20\n#base_max_searches = TBD</code></pre></div>","frontmatter":{"title":"Tuning Splunk when max concurrent searches are reached","date":"December 12, 2017","description":null}},"previous":{"fields":{"slug":"/2017/07/09/outage-due-to-ddos/"},"frontmatter":{"title":"Outage due to DDOS"}},"next":{"fields":{"slug":"/2018/01/09/can-we-even-patch-this-spectre-meltdown-oh-and-av-also/"},"frontmatter":{"title":"Can we even patch this Spectre/Meltdown oh and AV also"}}},"pageContext":{"id":"e97ea5a6-c280-5190-895b-32ec5bcc2673","previousPostId":"829bbf9f-4fc8-5c50-873a-5a05b75721c3","nextPostId":"7025e160-afd3-5f26-ae1a-8540a607cc7b"}},
    "staticQueryHashes": ["2841359383","3257411868"]}